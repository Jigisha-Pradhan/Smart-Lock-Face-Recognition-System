{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jigisha-Pradhan/Smart-Lock-Face-Recognition-System/blob/main/Face_Detection_based_door_lock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCYJV6uMmLMB",
        "outputId": "cb3fbf98-f7f4-40fd-b957-67159c3d97af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open known_faces, known_faces.zip or known_faces.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip known_faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUE5F3p97pmz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0783084-fdca-41a2-86e1-6f4bfa3587da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepface\n",
            "  Downloading deepface-0.0.93-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.2.2)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (5.2.0)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (4.67.1)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (11.1.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.11/dist-packages (from deepface) (4.11.0.86)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.18.0)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (3.8.0)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from deepface) (3.1.0)\n",
            "Collecting flask-cors>=4.0.1 (from deepface)\n",
            "  Downloading flask_cors-5.0.1-py3-none-any.whl.metadata (961 bytes)\n",
            "Collecting mtcnn>=0.1.0 (from deepface)\n",
            "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting retina-face>=0.0.1 (from deepface)\n",
            "  Downloading retina_face-0.0.17-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting fire>=0.4.0 (from deepface)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gunicorn>=20.1.0 (from deepface)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire>=0.4.0->deepface) (3.0.1)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (1.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface) (3.18.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gunicorn>=20.1.0->deepface) (24.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.4.1)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from mtcnn>=0.1.0->deepface) (1.4.2)\n",
            "Collecting lz4>=4.3.3 (from mtcnn>=0.1.0->deepface)\n",
            "  Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (2025.1.31)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (5.29.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (4.13.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (2.18.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.45.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask>=1.1.2->deepface) (3.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.9.0->deepface) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.9.0->deepface) (0.7.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.2.0->deepface) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.2.0->deepface) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\n",
            "Downloading deepface-0.0.93-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.6/108.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask_cors-5.0.1-py3-none-any.whl (11 kB)\n",
            "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retina_face-0.0.17-py3-none-any.whl (25 kB)\n",
            "Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=55cc3542fa94cccb3ced0ad079259c6c7925a9e91cc29db2363d7bfbed056872\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: lz4, gunicorn, fire, mtcnn, flask-cors, retina-face, deepface\n",
            "Successfully installed deepface-0.0.93 fire-0.7.0 flask-cors-5.0.1 gunicorn-23.0.0 lz4-4.4.4 mtcnn-1.0.0 retina-face-0.0.17\n"
          ]
        }
      ],
      "source": [
        "!pip install deepface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtMvs1INW9kh"
      },
      "outputs": [],
      "source": [
        "from deepface import DeepFace\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZvJBTAsiw3h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4045e7b6-6a48-4be3-dc25-4a0568c931e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12 files belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "# Assuming your images are in a folder named 'known_faces'\n",
        "dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    'known_faces',\n",
        "    labels='inferred',  # Infer labels from directory structure\n",
        "    label_mode='int',   # Integer encoded labels\n",
        "    image_size=(256, 256), # Resize images to 256x256\n",
        "    batch_size=32,      # Number of images per batch\n",
        "    shuffle=True        # Shuffle the dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCcM8dhbXdS1"
      },
      "outputs": [],
      "source": [
        "def load_dataset(dataset_path):\n",
        "    \"\"\"\n",
        "    Loads a dataset of images from the given path and extracts facial embeddings.\n",
        "\n",
        "    Args:\n",
        "        dataset_path (str): Path to the dataset directory.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - np.ndarray: Array of facial embeddings (X).\n",
        "            - np.ndarray: Array of corresponding labels (y).\n",
        "            Returns ([],[]) if no data found.\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    labels = os.listdir(dataset_path)\n",
        "\n",
        "    for label in labels:\n",
        "        person_path = os.path.join(dataset_path, label)\n",
        "        if os.path.isdir(person_path):\n",
        "            for img_name in os.listdir(person_path):\n",
        "                img_path = os.path.join(person_path, img_name)\n",
        "                try:\n",
        "                    embedding = DeepFace.represent(img_path, model_name=\"Facenet512\", enforce_detection=True)[0]['embedding']\n",
        "                    X.append(embedding)\n",
        "                    y.append(label)\n",
        "                except:\n",
        "                    print(f\"Skipping {img_path}, face not detected.\")\n",
        "    if not X:\n",
        "        print(f\"No data found in directory: {dataset_path}\")\n",
        "        return [], [] # Return empty lists as a tuple.\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def train_model(X, y):\n",
        "    \"\"\"\n",
        "    Trains a deep learning model on the given dataset.\n",
        "\n",
        "    Args:\n",
        "        X (np.ndarray): Array of features.\n",
        "        y (np.ndarray): Array of labels.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the trained model, scaler, and label_to_index mapping.\n",
        "        Raises Exception if no data found.\n",
        "    \"\"\"\n",
        "    if not X.size or not y.size:\n",
        "        raise ValueError(\"No data provided for training. Check load_dataset output.\")\n",
        "\n",
        "    if len(set(y)) < 2:\n",
        "        print(\"Not enough classes to train. Add more images per person.\")\n",
        "        raise ValueError(\"Not enough classes to train. Add more images per person.\")\n",
        "\n",
        "    print(f\"Training on {len(X)} samples across {len(set(y))} identities.\")\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    if len(set(y_train)) < 2:\n",
        "        print(\"Not enough classes in the training set. Increase dataset size.\")\n",
        "        raise ValueError(\"Not enough classes in the training set. Increase dataset size.\")\n",
        "\n",
        "    # Normalize features\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Handle class imbalance\n",
        "    class_counts = Counter(y_train)\n",
        "    min_samples = min(class_counts.values())\n",
        "\n",
        "    if min_samples > 1:\n",
        "        k = min(2, min_samples - 1)\n",
        "        smote = SMOTE(k_neighbors=k)\n",
        "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "    else:\n",
        "        print(\"Skipping SMOTE due to insufficient samples per class.\")\n",
        "\n",
        "    # Convert labels to categorical\n",
        "    unique_labels = list(set(y))\n",
        "    label_to_index = {label: i for i, label in enumerate(unique_labels)}\n",
        "    y_train = np.array([label_to_index[label] for label in y_train])\n",
        "    y_test = np.array([label_to_index[label] for label in y_test])\n",
        "    y_train = to_categorical(y_train, num_classes=len(unique_labels))\n",
        "    y_test = to_categorical(y_test, num_classes=len(unique_labels))\n",
        "\n",
        "    # Define a deep learning model\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(len(unique_labels), activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(X_train, y_train, epochs=20, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "    print(f\"Deep Learning Model Accuracy: {test_acc * 100:.2f}%\")\n",
        "\n",
        "    return model, scaler, label_to_index\n",
        "\n",
        "def verify_face(model, scaler, label_to_index, img_path):\n",
        "    \"\"\"\n",
        "    Verifies the identity of a face in an image.\n",
        "\n",
        "    Args:\n",
        "        model: The trained deep learning model.\n",
        "        scaler: The scaler used for feature normalization.\n",
        "        label_to_index: The mapping from label to index.\n",
        "        img_path (str): The path to the image.\n",
        "\n",
        "    Returns:\n",
        "        str: The predicted identity.\n",
        "        None: If not recognised.\n",
        "    \"\"\"\n",
        "    embedding = DeepFace.represent(img_path, model_name=\"Facenet512\", enforce_detection=True)[0]['embedding']\n",
        "    embedding = scaler.transform([embedding])\n",
        "    prediction = model.predict(embedding)\n",
        "    predicted_label = list(label_to_index.keys())[np.argmax(prediction)]\n",
        "    confidence = np.max(prediction) * 100\n",
        "    if(confidence>=70):\n",
        "        print(f\"Predicted Identity: {predicted_label}, Confidence: {confidence:.2f}%\")\n",
        "        return predicted_label\n",
        "    else:\n",
        "        print(\"Not recognised\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9JTfzD7Xu_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c6d0fcd-9b75-4693-eed1-24867e1e795a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25-03-29 13:59:49 - facenet512_weights.h5 will be downloaded...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/facenet512_weights.h5\n",
            "To: /root/.deepface/weights/facenet512_weights.h5\n",
            "100%|██████████| 95.0M/95.0M [00:00<00:00, 161MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping /content/known_faces/Bindu/bindhu2.jpg, face not detected.\n",
            "Training on 11 samples across 4 identities.\n",
            "Skipping SMOTE due to insufficient samples per class.\n",
            "Epoch 1/20\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.3699 - accuracy: 0.2500 - val_loss: 1.2583 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 1.1525 - accuracy: 0.6250 - val_loss: 0.8273 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6601 - accuracy: 0.7500 - val_loss: 0.5531 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4243 - accuracy: 0.8750 - val_loss: 0.3971 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.3907 - accuracy: 0.8750 - val_loss: 0.2865 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.2997 - accuracy: 0.8750 - val_loss: 0.2078 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1235 - accuracy: 1.0000 - val_loss: 0.1570 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1426 - accuracy: 0.8750 - val_loss: 0.1218 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1010 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.0624 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2167 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0171 - accuracy: 1.0000\n",
            "Deep Learning Model Accuracy: 100.00%\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "Predicted Identity: Jigisha, Confidence: 99.97%\n"
          ]
        }
      ],
      "source": [
        "dataset_path = \"/content/known_faces\"\n",
        "X, y = load_dataset(dataset_path)\n",
        "#Check if no data.\n",
        "if X.size == 0: # Check if the array is empty using .size\n",
        "    print(\"Exiting. No valid data found.\")\n",
        "else:\n",
        "    try:\n",
        "        model, scaler, label_to_index = train_model(X, y)\n",
        "    except ValueError as e:\n",
        "        print(f\"Failed to train: {e}\")\n",
        "\n",
        "        # Test the model\n",
        "        # Ensure model is trained before testing\n",
        "    if 'model' in locals():\n",
        "        test_img = \"TestJ1.jpg\"\n",
        "        predicted_identity = verify_face(model, scaler, label_to_index, test_img)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}